{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CohereEmbeddings",
            "id": "CohereEmbeddings-oTRiZ",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          },
          "targetHandle": {
            "fieldName": "embedding",
            "id": "FAISS-nMrj0",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-CohereEmbeddings-oTRiZ{œdataTypeœ:œCohereEmbeddingsœ,œidœ:œCohereEmbeddings-oTRiZœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-FAISS-nMrj0{œfieldNameœ:œembeddingœ,œidœ:œFAISS-nMrj0œ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CohereEmbeddings-oTRiZ",
        "sourceHandle": "{œdataTypeœ:œCohereEmbeddingsœ,œidœ:œCohereEmbeddings-oTRiZœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "target": "FAISS-nMrj0",
        "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œFAISS-nMrj0œ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "SplitText",
            "id": "SplitText-IvwOH",
            "name": "dataframe",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "ingest_data",
            "id": "FAISS-nMrj0",
            "inputTypes": [
              "Data",
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-SplitText-IvwOH{œdataTypeœ:œSplitTextœ,œidœ:œSplitText-IvwOHœ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}-FAISS-nMrj0{œfieldNameœ:œingest_dataœ,œidœ:œFAISS-nMrj0œ,œinputTypesœ:[œDataœ,œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "SplitText-IvwOH",
        "sourceHandle": "{œdataTypeœ:œSplitTextœ,œidœ:œSplitText-IvwOHœ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "FAISS-nMrj0",
        "targetHandle": "{œfieldNameœ:œingest_dataœ,œidœ:œFAISS-nMrj0œ,œinputTypesœ:[œDataœ,œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "FAISS",
            "id": "FAISS-nMrj0",
            "name": "dataframe",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "TypeConverterComponent-q42YN",
            "inputTypes": [
              "Message",
              "Data",
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-FAISS-nMrj0{œdataTypeœ:œFAISSœ,œidœ:œFAISS-nMrj0œ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}-TypeConverterComponent-q42YN{œfieldNameœ:œinput_dataœ,œidœ:œTypeConverterComponent-q42YNœ,œinputTypesœ:[œMessageœ,œDataœ,œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "FAISS-nMrj0",
        "sourceHandle": "{œdataTypeœ:œFAISSœ,œidœ:œFAISS-nMrj0œ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "TypeConverterComponent-q42YN",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œTypeConverterComponent-q42YNœ,œinputTypesœ:[œMessageœ,œDataœ,œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TypeConverterComponent",
            "id": "TypeConverterComponent-q42YN",
            "name": "message_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "search_results",
            "id": "Multilingual Prompt Template-m7jgv",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TypeConverterComponent-q42YN{œdataTypeœ:œTypeConverterComponentœ,œidœ:œTypeConverterComponent-q42YNœ,œnameœ:œmessage_outputœ,œoutput_typesœ:[œMessageœ]}-Multilingual Prompt Template-m7jgv{œfieldNameœ:œsearch_resultsœ,œidœ:œMultilingual Prompt Template-m7jgvœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TypeConverterComponent-q42YN",
        "sourceHandle": "{œdataTypeœ:œTypeConverterComponentœ,œidœ:œTypeConverterComponent-q42YNœ,œnameœ:œmessage_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Multilingual Prompt Template-m7jgv",
        "targetHandle": "{œfieldNameœ:œsearch_resultsœ,œidœ:œMultilingual Prompt Template-m7jgvœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CohereModel",
            "id": "CohereModel-7APO2",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "ai_response",
            "id": "MultilingualSmartTextProcessor-wCRnW",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-CohereModel-7APO2{œdataTypeœ:œCohereModelœ,œidœ:œCohereModel-7APO2œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-MultilingualSmartTextProcessor-wCRnW{œfieldNameœ:œai_responseœ,œidœ:œMultilingualSmartTextProcessor-wCRnWœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "CohereModel-7APO2",
        "sourceHandle": "{œdataTypeœ:œCohereModelœ,œidœ:œCohereModel-7APO2œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "MultilingualSmartTextProcessor-wCRnW",
        "targetHandle": "{œfieldNameœ:œai_responseœ,œidœ:œMultilingualSmartTextProcessor-wCRnWœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LanguageDetector",
            "id": "LanguageDetector-zZfnv",
            "name": "language",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "user_question",
            "id": "Multilingual Prompt Template-m7jgv",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-LanguageDetector-zZfnv{œdataTypeœ:œLanguageDetectorœ,œidœ:œLanguageDetector-zZfnvœ,œnameœ:œlanguageœ,œoutput_typesœ:[œMessageœ]}-Multilingual Prompt Template-m7jgv{œfieldNameœ:œuser_questionœ,œidœ:œMultilingual Prompt Template-m7jgvœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "LanguageDetector-zZfnv",
        "sourceHandle": "{œdataTypeœ:œLanguageDetectorœ,œidœ:œLanguageDetector-zZfnvœ,œnameœ:œlanguageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Multilingual Prompt Template-m7jgv",
        "targetHandle": "{œfieldNameœ:œuser_questionœ,œidœ:œMultilingual Prompt Template-m7jgvœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LanguageDetector",
            "id": "LanguageDetector-zZfnv",
            "name": "language",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "search_query",
            "id": "FAISS-nMrj0",
            "inputTypes": [
              "Message"
            ],
            "type": "query"
          }
        },
        "id": "reactflow__edge-LanguageDetector-zZfnv{œdataTypeœ:œLanguageDetectorœ,œidœ:œLanguageDetector-zZfnvœ,œnameœ:œlanguageœ,œoutput_typesœ:[œMessageœ]}-FAISS-nMrj0{œfieldNameœ:œsearch_queryœ,œidœ:œFAISS-nMrj0œ,œinputTypesœ:[œMessageœ],œtypeœ:œqueryœ}",
        "selected": false,
        "source": "LanguageDetector-zZfnv",
        "sourceHandle": "{œdataTypeœ:œLanguageDetectorœ,œidœ:œLanguageDetector-zZfnvœ,œnameœ:œlanguageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "FAISS-nMrj0",
        "targetHandle": "{œfieldNameœ:œsearch_queryœ,œidœ:œFAISS-nMrj0œ,œinputTypesœ:[œMessageœ],œtypeœ:œqueryœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-ByyGl",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "user_input",
            "id": "LanguageDetector-zZfnv",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ChatInput-ByyGl{œdataTypeœ:œChatInputœ,œidœ:œChatInput-ByyGlœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-LanguageDetector-zZfnv{œfieldNameœ:œuser_inputœ,œidœ:œLanguageDetector-zZfnvœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ChatInput-ByyGl",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-ByyGlœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "LanguageDetector-zZfnv",
        "targetHandle": "{œfieldNameœ:œuser_inputœ,œidœ:œLanguageDetector-zZfnvœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "MultilingualSmartTextProcessor",
            "id": "MultilingualSmartTextProcessor-wCRnW",
            "name": "result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-BsWFY",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-MultilingualSmartTextProcessor-wCRnW{œdataTypeœ:œMultilingualSmartTextProcessorœ,œidœ:œMultilingualSmartTextProcessor-wCRnWœ,œnameœ:œresultœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-BsWFY{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-BsWFYœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "MultilingualSmartTextProcessor-wCRnW",
        "sourceHandle": "{œdataTypeœ:œMultilingualSmartTextProcessorœ,œidœ:œMultilingualSmartTextProcessor-wCRnWœ,œnameœ:œresultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-BsWFY",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-BsWFYœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Multilingual Prompt Template",
            "id": "Multilingual Prompt Template-m7jgv",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "CohereModel-7APO2",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Multilingual Prompt Template-m7jgv{œdataTypeœ:œMultilingual Prompt Templateœ,œidœ:œMultilingual Prompt Template-m7jgvœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-CohereModel-7APO2{œfieldNameœ:œinput_valueœ,œidœ:œCohereModel-7APO2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Multilingual Prompt Template-m7jgv",
        "sourceHandle": "{œdataTypeœ:œMultilingual Prompt Templateœ,œidœ:œMultilingual Prompt Template-m7jgvœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CohereModel-7APO2",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œCohereModel-7APO2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-ByyGl",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "user_input",
            "id": "MultilingualSmartTextProcessor-wCRnW",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ChatInput-ByyGl{œdataTypeœ:œChatInputœ,œidœ:œChatInput-ByyGlœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-MultilingualSmartTextProcessor-wCRnW{œfieldNameœ:œuser_inputœ,œidœ:œMultilingualSmartTextProcessor-wCRnWœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ChatInput-ByyGl",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-ByyGlœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "MultilingualSmartTextProcessor-wCRnW",
        "targetHandle": "{œfieldNameœ:œuser_inputœ,œidœ:œMultilingualSmartTextProcessor-wCRnWœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "File",
            "id": "File-WJzcP",
            "name": "dataframe",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "data_inputs",
            "id": "SplitText-IvwOH",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-File-WJzcP{œdataTypeœ:œFileœ,œidœ:œFile-WJzcPœ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}-SplitText-IvwOH{œfieldNameœ:œdata_inputsœ,œidœ:œSplitText-IvwOHœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "File-WJzcP",
        "sourceHandle": "{œdataTypeœ:œFileœ,œidœ:œFile-WJzcPœ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "SplitText-IvwOH",
        "targetHandle": "{œfieldNameœ:œdata_inputsœ,œidœ:œSplitText-IvwOHœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "Multilingual Prompt Template-m7jgv",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "search_results",
                "user_question",
                "memory"
              ]
            },
            "description": "Create language-aware prompt templates with dynamic variables.",
            "display_name": "Multilingual Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": true,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.5.0.post1",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\r\nfrom langflow.custom.custom_component.component import Component\r\nfrom langflow.inputs.inputs import DefaultPromptField\r\nfrom langflow.io import MessageTextInput, Output, PromptInput\r\nfrom langflow.schema.message import Message\r\nfrom langflow.template.utils import update_template_values\r\nimport os\r\nimport re\r\n\r\nclass MultilingualPromptTemplate(Component):\r\n    display_name: str = \"Multilingual Prompt Template\"\r\n    description: str = \"Create language-aware prompt templates with dynamic variables.\"\r\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\r\n    icon = \"braces\"\r\n    trace_type = \"prompt\"\r\n    name = \"Multilingual Prompt Template\"\r\n    priority = 0\r\n    \r\n    inputs = [\r\n        PromptInput(name=\"template\", display_name=\"Template\"),\r\n        MessageTextInput(\r\n            name=\"tool_placeholder\",\r\n            display_name=\"Tool Placeholder\",\r\n            tool_mode=True,\r\n            advanced=True,\r\n            info=\"A placeholder input for tool mode.\",\r\n        ),\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\r\n    ]\r\n    \r\n    def _get_system_prompt(self, lang: str, base_template: str) -> str:\r\n        \"\"\"言語に応じたシステムプロンプトを生成\"\"\"\r\n        \r\n        # ベーステンプレートが存在する場合は、それをベースに言語指示を追加\r\n        if base_template and base_template.strip():\r\n            language_instructions = {\r\n                \"ja\": \"重要: 必ず日本語で回答してください。挨拶や質問促しも日本語で行ってください。回答の最後に追加のサポートメッセージは一切追加しないでください。\",\r\n                \"en\": \"IMPORTANT: Do NOT add any additional support messages or offers for help at the end of your response.\",\r\n                \"de\": \"WICHTIG: Bitte antworten Sie ausschließlich auf Deutsch. Fügen Sie KEINE zusätzlichen Hilfsangebote am Ende Ihrer Antwort hinzu.\",\r\n                \"pt\": \"Importante: Responda sempre em português. NÃO adicione mensagens de suporte adicionais no final da sua resposta.\"\r\n            }\r\n            \r\n            instruction = language_instructions.get(lang, \"\")\r\n            if instruction:\r\n                # ベーステンプレートの末尾に言語指示を追加\r\n                return base_template + \"\\n\\n\" + instruction\r\n            else:\r\n                return base_template\r\n        \r\n        # ベーステンプレートがない場合のフォールバック\r\n        fallback_prompts = {\r\n            \"ja\": \"\"\"あなたは親切なアシスタントです。提供されたドキュメントに基づいて、日本語で回答してください。\r\n\r\n重要: 回答の最後に追加のサポートメッセージや「他に質問はありますか？」のような文言は一切追加しないでください。質問に対する直接的な回答のみを提供してください。\r\n\r\nドキュメント: {search_results}\r\nユーザーの質問: {user_question}\r\n履歴: {memory}\r\n\r\n回答:\"\"\",\r\n            \r\n            \"en\": \"\"\"You are a helpful assistant. Based on the provided documents, answer the user's question.\r\n\r\nIMPORTANT: Do NOT add any additional support messages, offers for help, or phrases like \"Do you need further assistance?\" at the end of your response. Provide only the direct answer to the question.\r\n\r\nDocuments: {search_results}\r\nUser Question: {user_question}\r\nHistory: {memory}\r\n\r\nAnswer:\"\"\",\r\n            \r\n            \"de\": \"\"\"Sie sind ein hilfreicher Assistent. Basierend auf den bereitgestellten Dokumenten, beantworten Sie die Frage des Benutzers auf Deutsch.\r\n\r\nWICHTIG: Fügen Sie KEINE zusätzlichen Hilfsangebote oder Phrases wie \"Brauchen Sie weitere Hilfe?\" am Ende Ihrer Antwort hinzu. Geben Sie nur die direkte Antwort auf die Frage.\r\n\r\nDokumente: {search_results}\r\nBenutzerfrage: {user_question}\r\nVerlauf: {memory}\r\n\r\nAntwort:\"\"\",\r\n            \r\n            \"pt\": \"\"\"Você é um assistente útil. Com base nos documentos fornecidos, responda à pergunta do usuário em português.\r\n\r\nIMPORTANTE: NÃO adicione mensagens de suporte adicionais ou frases como \"Precisa de mais ajuda?\" no final da sua resposta. Forneça apenas a resposta direta à pergunta.\r\n\r\nDocumentos: {search_results}\r\nPergunta do Usuário: {user_question}\r\nHistórico: {memory}\r\n\r\nResposta:\"\"\"\r\n        }\r\n        \r\n        return fallback_prompts.get(lang, fallback_prompts[\"en\"])\r\n    \r\n    def _detect_language_direct(self, text: str) -> str:\r\n        \"\"\"入力テキストから直接言語を検出\"\"\"\r\n        print(f\"[DEBUG] === LANGUAGE DETECTION ===\")\r\n        print(f\"[DEBUG] Input text: '{text}' (length: {len(text) if text else 0})\")\r\n        \r\n        # 入力が空の場合、環境変数から前回の言語を取得\r\n        if not text or not text.strip():\r\n            existing_lang = os.environ.get(\"LANGFLOW_DETECTED_LANGUAGE\", \"ja\")  # デフォルトを日本語に\r\n            print(f\"[DEBUG] Empty input, using existing/default lang: {existing_lang}\")\r\n            return existing_lang\r\n        \r\n        # デバッグ用：入力テキストをログ出力\r\n        print(f\"[DEBUG] Input text analysis...\")\r\n        \r\n        # 継続入力の判定をより緩くする\r\n        if self._is_continuation_input(text):\r\n            existing_lang = os.environ.get(\"LANGFLOW_DETECTED_LANGUAGE\", \"ja\")\r\n            print(f\"[DEBUG] Continuation detected, using existing lang: {existing_lang}\")\r\n            return existing_lang\r\n        \r\n        # 日本語文字（ひらがな、カタカナ、漢字）の検出\r\n        hiragana_chars = re.findall(r'[\\u3040-\\u309F]', text)\r\n        katakana_chars = re.findall(r'[\\u30A0-\\u30FF]', text)\r\n        kanji_chars = re.findall(r'[\\u4e00-\\u9faf]', text)\r\n        \r\n        # 日本語特有の表現をチェック\r\n        japanese_patterns = [\r\n            r'エスクロ', r'ジャム', r'解除', r'の', r'を', r'に', r'が', r'は',\r\n            r'こんにち[はわ]', r'ありがと', r'です', r'ます', r'である', \r\n            r'について', r'してください', r'でしょう', r'だと思', r'おはよう',\r\n            r'何', r'どう', r'いつ', r'どこ', r'だれ', r'なぜ'\r\n        ]\r\n        \r\n        print(f\"[DEBUG] Japanese chars found - hiragana: {len(hiragana_chars)}, katakana: {len(katakana_chars)}, kanji: {len(kanji_chars)}\")\r\n        \r\n        # ひらがな・カタカナ・漢字があれば確実に日本語\r\n        if hiragana_chars or katakana_chars or kanji_chars:\r\n            print(f\"[DEBUG] Japanese detected by characters\")\r\n            return \"ja\"\r\n        \r\n        # 日本語特有の表現があれば日本語\r\n        for pattern in japanese_patterns:\r\n            if re.search(pattern, text):\r\n                print(f\"[DEBUG] Japanese detected by pattern: {pattern}\")\r\n                return \"ja\"\r\n        \r\n        # その他の言語チェック（簡略化）\r\n        if re.search(r'[äöüß]', text, re.IGNORECASE):\r\n            print(f\"[DEBUG] German detected\")\r\n            return \"de\"\r\n        \r\n        if re.search(r'[ãõç]', text, re.IGNORECASE):\r\n            print(f\"[DEBUG] Portuguese detected\")\r\n            return \"pt\"\r\n        \r\n        print(f\"[DEBUG] Default to Japanese (fallback for Japanese context)\")\r\n        return \"ja\"  # デフォルトを日本語に変更\r\n    \r\n    def _is_continuation_input(self, text: str) -> bool:\r\n        \"\"\"継続入力（Y/N）かどうかを判定 - より厳密に\"\"\"\r\n        if not text:\r\n            return False\r\n        \r\n        text_clean = text.strip().upper()\r\n        \r\n        # 短い単語のみを継続入力として判定\r\n        if len(text_clean) > 10:  # 10文字以上の場合は継続入力ではない\r\n            return False\r\n            \r\n        continuation_responses = [\"Y\", \"YES\", \"N\", \"NO\", \"はい\", \"いいえ\", \r\n                                \"JA\", \"NEIN\", \"SIM\", \"NÃO\"]\r\n        \r\n        return text_clean in [resp.upper() for resp in continuation_responses]\r\n    \r\n    def _get_user_input(self) -> str:\r\n        \"\"\"ユーザー入力を取得（全属性を総当たり）\"\"\"\r\n        user_input = \"\"\r\n        \r\n        print(f\"[DEBUG] === INPUT SOURCE DETECTION ===\")\r\n        print(f\"[DEBUG] Available attributes: {dir(self)}\")\r\n        \r\n        # すべての属性をチェック\r\n        for attr_name in dir(self):\r\n            if not attr_name.startswith('_'):\r\n                try:\r\n                    attr_value = getattr(self, attr_name)\r\n                    if attr_value and isinstance(attr_value, (str, int, float)) and str(attr_value).strip():\r\n                        print(f\"[DEBUG] Found non-empty attribute '{attr_name}': '{str(attr_value)}'\")\r\n                        if not user_input and len(str(attr_value)) > 2:  # 最初に見つかった意味のある値を使用\r\n                            user_input = str(attr_value)\r\n                            print(f\"[DEBUG] Using '{attr_name}' as user input\")\r\n                except:\r\n                    pass\r\n        \r\n        # _attributesも確認\r\n        if hasattr(self, '_attributes') and isinstance(self._attributes, dict):\r\n            print(f\"[DEBUG] _attributes keys: {list(self._attributes.keys())}\")\r\n            for key, value in self._attributes.items():\r\n                if value and isinstance(value, (str, int, float)) and str(value).strip():\r\n                    print(f\"[DEBUG] Found _attributes['{key}']: '{str(value)}'\")\r\n                    if not user_input and len(str(value)) > 2:\r\n                        user_input = str(value)\r\n                        print(f\"[DEBUG] Using _attributes['{key}'] as user input\")\r\n        \r\n        # 入力が見つからない場合の対策\r\n        if not user_input:\r\n            print(f\"[DEBUG] No user input found, checking for Japanese context...\")\r\n            # 環境変数やコンテキストから日本語を強制設定\r\n            if os.environ.get(\"LANGFLOW_DETECTED_LANGUAGE\") == \"ja\":\r\n                print(f\"[DEBUG] Maintaining Japanese context\")\r\n        \r\n        print(f\"[DEBUG] Final user input: '{user_input}'\")\r\n        return user_input\r\n    \r\n    async def build_prompt(self) -> Message:\r\n        # ユーザー入力を取得\r\n        user_input = self._get_user_input()\r\n        \r\n        # 直接言語検出\r\n        detected_lang = self._detect_language_direct(user_input)\r\n        \r\n        # 環境変数にも保存（継続入力でない場合のみ更新）\r\n        if not self._is_continuation_input(user_input):\r\n            os.environ[\"LANGFLOW_DETECTED_LANGUAGE\"] = detected_lang\r\n            print(f\"[DEBUG] Set environment language to: {detected_lang}\")\r\n        \r\n        # 元のテンプレートを取得\r\n        original_template = getattr(self, 'template', '') or ''\r\n        \r\n        # 言語に応じたプロンプトテンプレートを生成\r\n        language_aware_template = self._get_system_prompt(detected_lang, original_template)\r\n        \r\n        # 一時的にテンプレートを言語対応版に置き換え\r\n        original_template_attr = getattr(self, 'template', None)\r\n        self.template = language_aware_template\r\n        \r\n        try:\r\n            prompt = Message.from_template(**self._attributes)\r\n            # デバッグ情報を含めたステータス\r\n            is_continuation = self._is_continuation_input(user_input)\r\n            self.status = f\"Lang: {detected_lang} | Input: '{user_input[:30]}...' | IsCont: {is_continuation}\"\r\n            print(f\"[DEBUG] Final status: {self.status}\")\r\n            return prompt\r\n        finally:\r\n            # 元のテンプレートに戻す\r\n            self.template = original_template_attr\r\n    \r\n    def update_template(self, frontend_node: dict):\r\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\r\n        custom_fields = frontend_node[\"custom_fields\"]\r\n        frontend_node_template = frontend_node[\"template\"]\r\n        \r\n        updated_template = process_prompt_template(\r\n            template=template,\r\n            name=\"template\",\r\n            custom_fields=custom_fields,\r\n            frontend_node_template=frontend_node_template,\r\n        )\r\n        return frontend_node\r\n    \r\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\r\n        \"\"\"This function is called after the code validation is done.\"\"\"\r\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\r\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\r\n        \r\n        updated_template = process_prompt_template(\r\n            template=template,\r\n            name=\"template\",\r\n            custom_fields=frontend_node[\"custom_fields\"],\r\n            frontend_node_template=frontend_node[\"template\"],\r\n        )\r\n        \r\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\r\n        return frontend_node\r\n    \r\n    def get_fallback_input(self, **kwargs):\r\n        return DefaultPromptField(**kwargs)"
              },
              "memory": {
                "advanced": false,
                "display_name": "memory",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "search_results": {
                "advanced": false,
                "display_name": "search_results",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "search_results",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "You are a helpful assistant. Based on the provided documents, answer ONLY specific questions about the content.\n\nIf the user input is just a greeting (like \"Hello\", \"Hi\", etc.) or not a specific question, respond with a friendly greeting and ask what they would like to know about the documents.\n\nIf the user input is not related to the documents, respond briefly with: \"Sorry, I can't help with that. Please try rephrasing or asking in a different way.\"\n\nWhen answering long questions:\n- End partial answers with: \"\\n\\nContinue? (Yes/No)\"\n- If user says \"Yes\", continue the explanation from where you left off\n- If user says \"No\", offer to help with other questions\n\nIf the user asks a specific question, search the relevant information from the documents and provide a focused answer.\n\nOnly use excerpts from the documents that are in the same language as the user's question.  \nDo NOT translate excerpts from other languages or use them for the answer.  \nIf there are no excerpts in the same language, respond only with:  \n\"Sorry, I couldn't find relevant information in the documents.\"  \nDo not guess or use outside knowledge.\n\nResponse: Based on the following documents, answer the user's question. Only use information from the provided documents that is relevant to the question.\n\nDocuments: {search_results}\n\nUser Question: {user_question}\n\nHistory: {memory}\n\nAnswer:"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "user_question": {
                "advanced": false,
                "display_name": "user_question",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "user_question",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Multilingual Prompt Template"
        },
        "dragging": false,
        "id": "Multilingual Prompt Template-m7jgv",
        "measured": {
          "height": 545,
          "width": 320
        },
        "position": {
          "x": 781.7810896021074,
          "y": -638.335883210256
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "File-WJzcP",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "data",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Loads content from one or more files.",
            "display_name": "File",
            "documentation": "https://docs.langflow.org/components-data#file",
            "edited": false,
            "field_order": [
              "path",
              "file_path",
              "separator",
              "silent_errors",
              "delete_server_file_after_processing",
              "ignore_unsupported_extensions",
              "ignore_unspecified_files",
              "use_multithreading",
              "concurrency_multithreading"
            ],
            "frozen": false,
            "icon": "file-text",
            "key": "File",
            "last_updated": "2025-08-28T01:57:08.241Z",
            "legacy": false,
            "lf_version": "1.5.0.post1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Files",
                "group_outputs": false,
                "hidden": null,
                "method": "load_files",
                "name": "dataframe",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 2.220446049250313e-16,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from copy import deepcopy\nfrom typing import Any\n\nfrom langflow.base.data.base_file import BaseFileComponent\nfrom langflow.base.data.utils import TEXT_FILE_TYPES, parallel_load_data, parse_text_file_to_data\nfrom langflow.io import BoolInput, FileInput, IntInput, Output\nfrom langflow.schema.data import Data\n\n\nclass FileComponent(BaseFileComponent):\n    \"\"\"Handles loading and processing of individual or zipped text files.\n\n    This component supports processing multiple valid files within a zip archive,\n    resolving paths, validating file types, and optionally using multithreading for processing.\n    \"\"\"\n\n    display_name = \"File\"\n    description = \"Loads content from one or more files.\"\n    documentation: str = \"https://docs.langflow.org/components-data#file\"\n    icon = \"file-text\"\n    name = \"File\"\n\n    VALID_EXTENSIONS = TEXT_FILE_TYPES\n\n    _base_inputs = deepcopy(BaseFileComponent._base_inputs)\n\n    for input_item in _base_inputs:\n        if isinstance(input_item, FileInput) and input_item.name == \"path\":\n            input_item.real_time_refresh = True\n            break\n\n    inputs = [\n        *_base_inputs,\n        BoolInput(\n            name=\"use_multithreading\",\n            display_name=\"[Deprecated] Use Multithreading\",\n            advanced=True,\n            value=True,\n            info=\"Set 'Processing Concurrency' greater than 1 to enable multithreading.\",\n        ),\n        IntInput(\n            name=\"concurrency_multithreading\",\n            display_name=\"Processing Concurrency\",\n            advanced=True,\n            info=\"When multiple files are being processed, the number of files to process concurrently.\",\n            value=1,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Raw Content\", name=\"message\", method=\"load_files_message\"),\n    ]\n\n    def update_outputs(self, frontend_node: dict, field_name: str, field_value: Any) -> dict:\n        \"\"\"Dynamically show only the relevant output based on the number of files processed.\"\"\"\n        if field_name == \"path\":\n            # Add outputs based on the number of files in the path\n            if len(field_value) == 0:\n                return frontend_node\n\n            frontend_node[\"outputs\"] = []\n\n            if len(field_value) == 1:\n                # We need to check if the file is structured content\n                file_path = frontend_node[\"template\"][\"path\"][\"file_path\"][0]\n                if file_path.endswith((\".csv\", \".xlsx\", \".parquet\")):\n                    frontend_node[\"outputs\"].append(\n                        Output(display_name=\"Structured Content\", name=\"dataframe\", method=\"load_files_structured\"),\n                    )\n                elif file_path.endswith(\".json\"):\n                    frontend_node[\"outputs\"].append(\n                        Output(display_name=\"Structured Content\", name=\"json\", method=\"load_files_json\"),\n                    )\n\n                # All files get the raw content and path outputs\n                frontend_node[\"outputs\"].append(\n                    Output(display_name=\"Raw Content\", name=\"message\", method=\"load_files_message\"),\n                )\n                frontend_node[\"outputs\"].append(\n                    Output(display_name=\"File Path\", name=\"path\", method=\"load_files_path\"),\n                )\n            else:\n                # For multiple files, we only show the files output\n                frontend_node[\"outputs\"].append(\n                    Output(display_name=\"Files\", name=\"dataframe\", method=\"load_files\"),\n                )\n\n        return frontend_node\n\n    def process_files(self, file_list: list[BaseFileComponent.BaseFile]) -> list[BaseFileComponent.BaseFile]:\n        \"\"\"Processes files either sequentially or in parallel, depending on concurrency settings.\n\n        Args:\n            file_list (list[BaseFileComponent.BaseFile]): List of files to process.\n\n        Returns:\n            list[BaseFileComponent.BaseFile]: Updated list of files with merged data.\n        \"\"\"\n\n        def process_file(file_path: str, *, silent_errors: bool = False) -> Data | None:\n            \"\"\"Processes a single file and returns its Data object.\"\"\"\n            try:\n                return parse_text_file_to_data(file_path, silent_errors=silent_errors)\n            except FileNotFoundError as e:\n                msg = f\"File not found: {file_path}. Error: {e}\"\n                self.log(msg)\n                if not silent_errors:\n                    raise\n                return None\n            except Exception as e:\n                msg = f\"Unexpected error processing {file_path}: {e}\"\n                self.log(msg)\n                if not silent_errors:\n                    raise\n                return None\n\n        if not file_list:\n            msg = \"No files to process.\"\n            raise ValueError(msg)\n\n        concurrency = 1 if not self.use_multithreading else max(1, self.concurrency_multithreading)\n        file_count = len(file_list)\n\n        parallel_processing_threshold = 2\n        if concurrency < parallel_processing_threshold or file_count < parallel_processing_threshold:\n            if file_count > 1:\n                self.log(f\"Processing {file_count} files sequentially.\")\n            processed_data = [process_file(str(file.path), silent_errors=self.silent_errors) for file in file_list]\n        else:\n            self.log(f\"Starting parallel processing of {file_count} files with concurrency: {concurrency}.\")\n            file_paths = [str(file.path) for file in file_list]\n            processed_data = parallel_load_data(\n                file_paths,\n                silent_errors=self.silent_errors,\n                load_function=process_file,\n                max_concurrency=concurrency,\n            )\n\n        # Use rollup_basefile_data to merge processed data with BaseFile objects\n        return self.rollup_data(file_list, processed_data)\n"
              },
              "concurrency_multithreading": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Processing Concurrency",
                "dynamic": false,
                "info": "When multiple files are being processed, the number of files to process concurrently.",
                "list": false,
                "list_add_label": "Add More",
                "name": "concurrency_multithreading",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "delete_server_file_after_processing": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Delete Server File After Processing",
                "dynamic": false,
                "info": "If true, the Server File Path will be deleted after processing.",
                "list": false,
                "list_add_label": "Add More",
                "name": "delete_server_file_after_processing",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "file_path": {
                "_input_type": "HandleInput",
                "advanced": true,
                "display_name": "Server File Path",
                "dynamic": false,
                "info": "Data object with a 'file_path' property pointing to server file or a Message object with a path to the file. Supercedes 'Path' but supports same file types.",
                "input_types": [
                  "Data",
                  "Message"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "file_path",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "ignore_unspecified_files": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Ignore Unspecified Files",
                "dynamic": false,
                "info": "If true, Data with no 'file_path' property will be ignored.",
                "list": false,
                "list_add_label": "Add More",
                "name": "ignore_unspecified_files",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "ignore_unsupported_extensions": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Ignore Unsupported Extensions",
                "dynamic": false,
                "info": "If true, files with unsupported extensions will not be processed.",
                "list": false,
                "list_add_label": "Add More",
                "name": "ignore_unsupported_extensions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "path": {
                "_input_type": "FileInput",
                "advanced": false,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "zip",
                  "tar",
                  "tgz",
                  "bz2",
                  "gz"
                ],
                "file_path": [
                  "34159ae4-4220-4bcb-82e2-5a4afc3460ce/MRX_PreventiveMaintenance_en.txt",
                  "34159ae4-4220-4bcb-82e2-5a4afc3460ce/MRX_PreventiveMaintenance_ja.txt"
                ],
                "info": "Supported file extensions: txt, md, mdx, csv, json, yaml, yml, xml, html, htm, pdf, docx, py, sh, sql, js, ts, tsx; optionally bundled in file extensions: zip, tar, tgz, bz2, gz",
                "list": true,
                "list_add_label": "Add More",
                "name": "path",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "temp_file": false,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "separator": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "Specify the separator to use between multiple outputs in Message format.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "separator",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n\n"
              },
              "silent_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Silent Errors",
                "dynamic": false,
                "info": "If true, errors will not raise an exception.",
                "list": false,
                "list_add_label": "Add More",
                "name": "silent_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "use_multithreading": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "[Deprecated] Use Multithreading",
                "dynamic": false,
                "info": "Set 'Processing Concurrency' greater than 1 to enable multithreading.",
                "list": false,
                "list_add_label": "Add More",
                "name": "use_multithreading",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "selected_output": "message",
          "showNode": true,
          "type": "File"
        },
        "dragging": false,
        "id": "File-WJzcP",
        "measured": {
          "height": 261,
          "width": 320
        },
        "position": {
          "x": -678.8469599974421,
          "y": -961.9472527690901
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatInput-ByyGl",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "https://docs.langflow.org/components-io#chat-input",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "key": "ChatInput",
            "legacy": false,
            "lf_version": "1.5.0.post1",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chat Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.0020353564437605998,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs.inputs import BoolInput\nfrom langflow.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-input\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n            temp_file=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Chat Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        background_color = self.background_color\n        text_color = self.text_color\n        icon = self.chat_icon\n\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\n                \"background_color\": background_color,\n                \"text_color\": text_color,\n                \"icon\": icon,\n            },\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "files": {
                "_input_type": "FileInput",
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "list_add_label": "Add More",
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "temp_file": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Input Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatInput"
        },
        "dragging": false,
        "id": "ChatInput-ByyGl",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": -508.21119834875134,
          "y": -159.49975234698752
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-BsWFY",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "https://docs.langflow.org/components-io#chat-output",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "key": "ChatOutput",
            "legacy": false,
            "lf_version": "1.5.0.post1",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.003169567463043492,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.template.field.base import Output\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([safe_convert(item, clean_data=self.clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-BsWFY",
        "measured": {
          "height": 165,
          "width": 320
        },
        "position": {
          "x": 1881.1375378604512,
          "y": -207.5131797742286
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "FAISS-nMrj0",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "beta": false,
            "category": "vectorstores",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "FAISS Vector Store with search capabilities",
            "display_name": "FAISS",
            "documentation": "",
            "edited": false,
            "field_order": [
              "index_name",
              "persist_directory",
              "ingest_data",
              "search_query",
              "should_cache_vector_store",
              "allow_dangerous_deserialization",
              "embedding",
              "number_of_results"
            ],
            "frozen": false,
            "icon": "FAISS",
            "key": "FAISS",
            "legacy": false,
            "lf_version": "1.5.0.post1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Search Results",
                "group_outputs": false,
                "method": "search_documents",
                "name": "search_results",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "group_outputs": false,
                "method": "as_dataframe",
                "name": "dataframe",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 1.3256846433581093e-17,
            "template": {
              "_type": "Component",
              "allow_dangerous_deserialization": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Allow Dangerous Deserialization",
                "dynamic": false,
                "info": "Set to True to allow loading pickle files from untrusted sources. Only enable this if you trust the source of the data.",
                "list": false,
                "list_add_label": "Add More",
                "name": "allow_dangerous_deserialization",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from pathlib import Path\n\nfrom langchain_community.vectorstores import FAISS\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom langflow.helpers.data import docs_to_data\nfrom langflow.io import BoolInput, HandleInput, IntInput, StrInput\nfrom langflow.schema.data import Data\n\n\nclass FaissVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"FAISS Vector Store with search capabilities.\"\"\"\n\n    display_name: str = \"FAISS\"\n    description: str = \"FAISS Vector Store with search capabilities\"\n    name = \"FAISS\"\n    icon = \"FAISS\"\n\n    inputs = [\n        StrInput(\n            name=\"index_name\",\n            display_name=\"Index Name\",\n            value=\"langflow_index\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"Persist Directory\",\n            info=\"Path to save the FAISS index. It will be relative to where Langflow is running.\",\n        ),\n        *LCVectorStoreComponent.inputs,\n        BoolInput(\n            name=\"allow_dangerous_deserialization\",\n            display_name=\"Allow Dangerous Deserialization\",\n            info=\"Set to True to allow loading pickle files from untrusted sources. \"\n            \"Only enable this if you trust the source of the data.\",\n            advanced=True,\n            value=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n    ]\n\n    @staticmethod\n    def resolve_path(path: str) -> str:\n        \"\"\"Resolve the path relative to the Langflow root.\n\n        Args:\n            path: The path to resolve\n        Returns:\n            str: The resolved path as a string\n        \"\"\"\n        return str(Path(path).resolve())\n\n    def get_persist_directory(self) -> Path:\n        \"\"\"Returns the resolved persist directory path or the current directory if not set.\"\"\"\n        if self.persist_directory:\n            return Path(self.resolve_path(self.persist_directory))\n        return Path()\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> FAISS:\n        \"\"\"Builds the FAISS object.\"\"\"\n        path = self.get_persist_directory()\n        path.mkdir(parents=True, exist_ok=True)\n\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        faiss = FAISS.from_documents(documents=documents, embedding=self.embedding)\n        faiss.save_local(str(path), self.index_name)\n        return faiss\n\n    def search_documents(self) -> list[Data]:\n        \"\"\"Search for documents in the FAISS vector store.\"\"\"\n        path = self.get_persist_directory()\n        index_path = path / f\"{self.index_name}.faiss\"\n\n        if not index_path.exists():\n            vector_store = self.build_vector_store()\n        else:\n            vector_store = FAISS.load_local(\n                folder_path=str(path),\n                embeddings=self.embedding,\n                index_name=self.index_name,\n                allow_dangerous_deserialization=self.allow_dangerous_deserialization,\n            )\n\n        if not vector_store:\n            msg = \"Failed to load the FAISS index.\"\n            raise ValueError(msg)\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n            return docs_to_data(docs)\n        return []\n"
              },
              "embedding": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Embedding",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Embeddings"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "embedding",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "index_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Index Name",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "index_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "langflow_index"
              },
              "ingest_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Ingest Data",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data",
                  "DataFrame"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "ingest_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "number_of_results": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Results",
                "dynamic": false,
                "info": "Number of results to return.",
                "list": false,
                "list_add_label": "Add More",
                "name": "number_of_results",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 4
              },
              "persist_directory": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Persist Directory",
                "dynamic": false,
                "info": "Path to save the FAISS index. It will be relative to where Langflow is running.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "persist_directory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "./faiss_db_refresh"
              },
              "search_query": {
                "_input_type": "QueryInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "Enter a query to run a similarity search.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "search_query",
                "placeholder": "Enter a query...",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "query",
                "value": ""
              },
              "should_cache_vector_store": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Cache Vector Store",
                "dynamic": false,
                "info": "If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_cache_vector_store",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "selected_output": "dataframe",
          "showNode": true,
          "type": "FAISS"
        },
        "dragging": false,
        "id": "FAISS-nMrj0",
        "measured": {
          "height": 454,
          "width": 320
        },
        "position": {
          "x": 68.77434454442425,
          "y": -907.1843522923203
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CohereEmbeddings-oTRiZ",
          "node": {
            "base_classes": [
              "Embeddings"
            ],
            "beta": false,
            "category": "cohere",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate embeddings using Cohere models.",
            "display_name": "Cohere Embeddings",
            "documentation": "",
            "edited": false,
            "field_order": [
              "api_key",
              "model_name",
              "truncate",
              "max_retries",
              "user_agent",
              "request_timeout"
            ],
            "frozen": false,
            "icon": "Cohere",
            "key": "CohereEmbeddings",
            "last_updated": "2025-08-28T01:57:08.242Z",
            "legacy": false,
            "lf_version": "1.5.0.post1",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Embeddings",
                "group_outputs": false,
                "method": "build_embeddings",
                "name": "embeddings",
                "options": null,
                "required_inputs": null,
                "selected": "Embeddings",
                "tool_mode": true,
                "types": [
                  "Embeddings"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 1.680506611692e-18,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Cohere API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "Cohere API Key"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nimport cohere\nfrom langchain_cohere import CohereEmbeddings\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import DropdownInput, FloatInput, IntInput, MessageTextInput, Output, SecretStrInput\n\nHTTP_STATUS_OK = 200\n\n\nclass CohereEmbeddingsComponent(LCModelComponent):\n    display_name = \"Cohere Embeddings\"\n    description = \"Generate embeddings using Cohere models.\"\n    icon = \"Cohere\"\n    name = \"CohereEmbeddings\"\n\n    inputs = [\n        SecretStrInput(name=\"api_key\", display_name=\"Cohere API Key\", required=True, real_time_refresh=True),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model\",\n            advanced=False,\n            options=[\n                \"embed-english-v2.0\",\n                \"embed-multilingual-v2.0\",\n                \"embed-english-light-v2.0\",\n                \"embed-multilingual-light-v2.0\",\n            ],\n            value=\"embed-english-v2.0\",\n            refresh_button=True,\n            combobox=True,\n        ),\n        MessageTextInput(name=\"truncate\", display_name=\"Truncate\", advanced=True),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        MessageTextInput(name=\"user_agent\", display_name=\"User Agent\", advanced=True, value=\"langchain\"),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        data = None\n        try:\n            data = CohereEmbeddings(\n                cohere_api_key=self.api_key,\n                model=self.model_name,\n                truncate=self.truncate,\n                max_retries=self.max_retries,\n                user_agent=self.user_agent,\n                request_timeout=self.request_timeout or None,\n            )\n        except Exception as e:\n            msg = (\n                \"Unable to create Cohere Embeddings. \",\n                \"Please verify the API key and model parameters, and try again.\",\n            )\n            raise ValueError(msg) from e\n        # added status if not the return data would be serialised to create the status\n        return data\n\n    def get_model(self):\n        try:\n            co = cohere.ClientV2(self.api_key)\n            response = co.models.list(endpoint=\"embed\")\n            models = response.models\n            return [model.name for model in models]\n        except Exception as e:\n            msg = f\"Failed to fetch Cohere models. Error: {e}\"\n            raise ValueError(msg) from e\n\n    async def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None):\n        if field_name in {\"model_name\", \"api_key\"}:\n            if build_config.get(\"api_key\", {}).get(\"value\", None):\n                build_config[\"model_name\"][\"options\"] = self.get_model()\n        else:\n            build_config[\"model_name\"][\"options\"] = field_value\n        return build_config\n"
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 3
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model",
                "dynamic": false,
                "info": "",
                "name": "model_name",
                "options": [
                  "embed-english-light-v3.0",
                  "embed-multilingual-v2.0",
                  "embed-english-v3.0",
                  "embed-v4.0",
                  "embed-english-v2.0",
                  "embed-multilingual-light-v3.0",
                  "embed-multilingual-v3.0",
                  "embed-english-light-v2.0"
                ],
                "options_metadata": [],
                "placeholder": "",
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "embed-multilingual-v3.0"
              },
              "request_timeout": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Request Timeout",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "request_timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": ""
              },
              "truncate": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Truncate",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "truncate",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "user_agent": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "User Agent",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "user_agent",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "langchain"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "CohereEmbeddings"
        },
        "dragging": false,
        "id": "CohereEmbeddings-oTRiZ",
        "measured": {
          "height": 284,
          "width": 320
        },
        "position": {
          "x": -300.73018279586006,
          "y": -680.8680786759064
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TypeConverterComponent-q42YN",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert between different types (Message, Data, DataFrame)",
            "display_name": "Type Convert",
            "documentation": "https://docs.langflow.org/components-processing#type-convert",
            "edited": false,
            "field_order": [
              "input_data",
              "output_type"
            ],
            "frozen": false,
            "icon": "repeat",
            "key": "TypeConverterComponent",
            "legacy": false,
            "lf_version": "1.5.0.post1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message Output",
                "group_outputs": false,
                "method": "convert_to_message",
                "name": "message_output",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langflow.custom import Component\nfrom langflow.io import HandleInput, Output, TabInput\nfrom langflow.schema import Data, DataFrame, Message\n\n\ndef convert_to_message(v) -> Message:\n    \"\"\"Convert input to Message type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        Message: Converted Message object\n    \"\"\"\n    return v if isinstance(v, Message) else v.to_message()\n\n\ndef convert_to_data(v: DataFrame | Data | Message | dict) -> Data:\n    \"\"\"Convert input to Data type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        Data: Converted Data object\n    \"\"\"\n    if isinstance(v, dict):\n        return Data(v)\n    if isinstance(v, Message):\n        return v.to_data()\n    return v if isinstance(v, Data) else v.to_data()\n\n\ndef convert_to_dataframe(v: DataFrame | Data | Message | dict) -> DataFrame:\n    \"\"\"Convert input to DataFrame type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        DataFrame: Converted DataFrame object\n    \"\"\"\n    if isinstance(v, dict):\n        return DataFrame([v])\n    return v if isinstance(v, DataFrame) else v.to_dataframe()\n\n\nclass TypeConverterComponent(Component):\n    display_name = \"Type Convert\"\n    description = \"Convert between different types (Message, Data, DataFrame)\"\n    documentation: str = \"https://docs.langflow.org/components-processing#type-convert\"\n    icon = \"repeat\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Input\",\n            input_types=[\"Message\", \"Data\", \"DataFrame\"],\n            info=\"Accept Message, Data or DataFrame as input\",\n            required=True,\n        ),\n        TabInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Message\", \"Data\", \"DataFrame\"],\n            info=\"Select the desired output data type\",\n            real_time_refresh=True,\n            value=\"Message\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message Output\",\n            name=\"message_output\",\n            method=\"convert_to_message\",\n        )\n    ]\n\n    def update_outputs(self, frontend_node: dict, field_name: str, field_value: Any) -> dict:\n        \"\"\"Dynamically show only the relevant output based on the selected output type.\"\"\"\n        if field_name == \"output_type\":\n            # Start with empty outputs\n            frontend_node[\"outputs\"] = []\n\n            # Add only the selected output type\n            if field_value == \"Message\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"Message Output\",\n                        name=\"message_output\",\n                        method=\"convert_to_message\",\n                    ).to_dict()\n                )\n            elif field_value == \"Data\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"Data Output\",\n                        name=\"data_output\",\n                        method=\"convert_to_data\",\n                    ).to_dict()\n                )\n            elif field_value == \"DataFrame\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"DataFrame Output\",\n                        name=\"dataframe_output\",\n                        method=\"convert_to_dataframe\",\n                    ).to_dict()\n                )\n\n        return frontend_node\n\n    def convert_to_message(self) -> Message:\n        \"\"\"Convert input to Message type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_message(input_value)\n        self.status = result\n        return result\n\n    def convert_to_data(self) -> Data:\n        \"\"\"Convert input to Data type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_data(input_value)\n        self.status = result\n        return result\n\n    def convert_to_dataframe(self) -> DataFrame:\n        \"\"\"Convert input to DataFrame type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_dataframe(input_value)\n        self.status = result\n        return result\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "Accept Message, Data or DataFrame as input",
                "input_types": [
                  "Message",
                  "Data",
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "output_type": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Output Type",
                "dynamic": false,
                "info": "Select the desired output data type",
                "name": "output_type",
                "options": [
                  "Message",
                  "Data",
                  "DataFrame"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Message"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TypeConverterComponent"
        },
        "dragging": false,
        "id": "TypeConverterComponent-q42YN",
        "measured": {
          "height": 261,
          "width": 320
        },
        "position": {
          "x": 420.493792226358,
          "y": -710.1663466514681
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "SplitText-IvwOH",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Split text into chunks based on specified criteria.",
            "display_name": "Split Text",
            "documentation": "https://docs.langflow.org/components-processing#split-text",
            "edited": false,
            "field_order": [
              "data_inputs",
              "chunk_overlap",
              "chunk_size",
              "separator",
              "text_key",
              "keep_separator"
            ],
            "frozen": false,
            "icon": "scissors-line-dashed",
            "key": "SplitText",
            "legacy": false,
            "lf_version": "1.5.0.post1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chunks",
                "group_outputs": false,
                "method": "split_text",
                "name": "dataframe",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.0006561452663029057,
            "template": {
              "_type": "Component",
              "chunk_overlap": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Chunk Overlap",
                "dynamic": false,
                "info": "Number of characters to overlap between chunks.",
                "list": false,
                "list_add_label": "Add More",
                "name": "chunk_overlap",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 200
              },
              "chunk_size": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Chunk Size",
                "dynamic": false,
                "info": "The maximum length of each chunk. Text is first split by separator, then chunks are merged up to this size. Individual splits larger than this won't be further divided.",
                "list": false,
                "list_add_label": "Add More",
                "name": "chunk_size",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1000
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_text_splitters import CharacterTextSplitter\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import DropdownInput, HandleInput, IntInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.utils.util import unescape_string\n\n\nclass SplitTextComponent(Component):\n    display_name: str = \"Split Text\"\n    description: str = \"Split text into chunks based on specified criteria.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#split-text\"\n    icon = \"scissors-line-dashed\"\n    name = \"SplitText\"\n\n    inputs = [\n        HandleInput(\n            name=\"data_inputs\",\n            display_name=\"Input\",\n            info=\"The data with texts to split in chunks.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"Number of characters to overlap between chunks.\",\n            value=200,\n        ),\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=(\n                \"The maximum length of each chunk. Text is first split by separator, \"\n                \"then chunks are merged up to this size. \"\n                \"Individual splits larger than this won't be further divided.\"\n            ),\n            value=1000,\n        ),\n        MessageTextInput(\n            name=\"separator\",\n            display_name=\"Separator\",\n            info=(\n                \"The character to split on. Use \\\\n for newline. \"\n                \"Examples: \\\\n\\\\n for paragraphs, \\\\n for lines, . for sentences\"\n            ),\n            value=\"\\n\",\n        ),\n        MessageTextInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"The key to use for the text column.\",\n            value=\"text\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"keep_separator\",\n            display_name=\"Keep Separator\",\n            info=\"Whether to keep the separator in the output chunks and where to place it.\",\n            options=[\"False\", \"True\", \"Start\", \"End\"],\n            value=\"False\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Chunks\", name=\"dataframe\", method=\"split_text\"),\n    ]\n\n    def _docs_to_data(self, docs) -> list[Data]:\n        return [Data(text=doc.page_content, data=doc.metadata) for doc in docs]\n\n    def _fix_separator(self, separator: str) -> str:\n        \"\"\"Fix common separator issues and convert to proper format.\"\"\"\n        if separator == \"/n\":\n            return \"\\n\"\n        if separator == \"/t\":\n            return \"\\t\"\n        return separator\n\n    def split_text_base(self):\n        separator = self._fix_separator(self.separator)\n        separator = unescape_string(separator)\n\n        if isinstance(self.data_inputs, DataFrame):\n            if not len(self.data_inputs):\n                msg = \"DataFrame is empty\"\n                raise TypeError(msg)\n\n            self.data_inputs.text_key = self.text_key\n            try:\n                documents = self.data_inputs.to_lc_documents()\n            except Exception as e:\n                msg = f\"Error converting DataFrame to documents: {e}\"\n                raise TypeError(msg) from e\n        elif isinstance(self.data_inputs, Message):\n            self.data_inputs = [self.data_inputs.to_data()]\n            return self.split_text_base()\n        else:\n            if not self.data_inputs:\n                msg = \"No data inputs provided\"\n                raise TypeError(msg)\n\n            documents = []\n            if isinstance(self.data_inputs, Data):\n                self.data_inputs.text_key = self.text_key\n                documents = [self.data_inputs.to_lc_document()]\n            else:\n                try:\n                    documents = [input_.to_lc_document() for input_ in self.data_inputs if isinstance(input_, Data)]\n                    if not documents:\n                        msg = f\"No valid Data inputs found in {type(self.data_inputs)}\"\n                        raise TypeError(msg)\n                except AttributeError as e:\n                    msg = f\"Invalid input type in collection: {e}\"\n                    raise TypeError(msg) from e\n        try:\n            # Convert string 'False'/'True' to boolean\n            keep_sep = self.keep_separator\n            if isinstance(keep_sep, str):\n                if keep_sep.lower() == \"false\":\n                    keep_sep = False\n                elif keep_sep.lower() == \"true\":\n                    keep_sep = True\n                # 'start' and 'end' are kept as strings\n\n            splitter = CharacterTextSplitter(\n                chunk_overlap=self.chunk_overlap,\n                chunk_size=self.chunk_size,\n                separator=separator,\n                keep_separator=keep_sep,\n            )\n            return splitter.split_documents(documents)\n        except Exception as e:\n            msg = f\"Error splitting text: {e}\"\n            raise TypeError(msg) from e\n\n    def split_text(self) -> DataFrame:\n        return DataFrame(self._docs_to_data(self.split_text_base()))\n"
              },
              "data_inputs": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The data with texts to split in chunks.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "data_inputs",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "keep_separator": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Keep Separator",
                "dynamic": false,
                "info": "Whether to keep the separator in the output chunks and where to place it.",
                "name": "keep_separator",
                "options": [
                  "False",
                  "True",
                  "Start",
                  "End"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "False"
              },
              "separator": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Separator",
                "dynamic": false,
                "info": "The character to split on. Use \\n for newline. Examples: \\n\\n for paragraphs, \\n for lines, . for sentences",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "separator",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "[\"\\n\\n\", \"\\n\", \" \"]"
              },
              "text_key": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Key",
                "dynamic": false,
                "info": "The key to use for the text column.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "text"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "SplitText"
        },
        "dragging": false,
        "id": "SplitText-IvwOH",
        "measured": {
          "height": 410,
          "width": 320
        },
        "position": {
          "x": -293.10180969399227,
          "y": -1113.3637096208251
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CohereModel-7APO2",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "cohere",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate text using Cohere LLMs.",
            "display_name": "Cohere Language Models",
            "documentation": "https://python.langchain.com/docs/modules/model_io/models/llms/integrations/cohere",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "cohere_api_key",
              "temperature"
            ],
            "frozen": false,
            "icon": "Cohere",
            "key": "CohereModel",
            "legacy": false,
            "lf_version": "1.5.0.post1",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "method": "text_response",
                "name": "text_output",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "method": "build_model",
                "name": "model_output",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 2.009095743410637e-18,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_cohere import ChatCohere\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.io import SecretStrInput, SliderInput\n\n\nclass CohereComponent(LCModelComponent):\n    display_name = \"Cohere Language Models\"\n    description = \"Generate text using Cohere LLMs.\"\n    documentation = \"https://python.langchain.com/docs/modules/model_io/models/llms/integrations/cohere\"\n    icon = \"Cohere\"\n    name = \"CohereModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        SecretStrInput(\n            name=\"cohere_api_key\",\n            display_name=\"Cohere API Key\",\n            info=\"The Cohere API Key to use for the Cohere model.\",\n            advanced=False,\n            value=\"COHERE_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.75,\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\n            info=\"Controls randomness. Lower values are more deterministic, higher values are more creative.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        cohere_api_key = self.cohere_api_key\n        temperature = self.temperature\n\n        api_key = SecretStr(cohere_api_key).get_secret_value() if cohere_api_key else None\n\n        return ChatCohere(\n            temperature=temperature or 0.75,\n            cohere_api_key=api_key,\n        )\n"
              },
              "cohere_api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Cohere API Key",
                "dynamic": false,
                "info": "The Cohere API Key to use for the Cohere model.",
                "input_types": [],
                "load_from_db": true,
                "name": "cohere_api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "Cohere API Key"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness. Lower values are more deterministic, higher values are more creative.",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.75
              }
            },
            "tool_mode": false
          },
          "selected_output": "text_output",
          "showNode": true,
          "type": "CohereModel"
        },
        "dragging": false,
        "id": "CohereModel-7APO2",
        "measured": {
          "height": 366,
          "width": 320
        },
        "position": {
          "x": 1128.8127999287167,
          "y": -428.173044733685
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "MultilingualSmartTextProcessor-wCRnW",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Handle text length with multi-language support and natural text splitting",
            "display_name": "Multilingual Smart Text Processor",
            "documentation": "",
            "edited": true,
            "field_order": [
              "ai_response",
              "user_input"
            ],
            "frozen": false,
            "legacy": false,
            "lf_version": "1.5.0.post1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Result",
                "group_outputs": false,
                "hidden": null,
                "method": "process_text",
                "name": "result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "ai_response": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "AI Response",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "ai_response",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\r\nfrom langflow.io import MessageTextInput, Output\r\nfrom langflow.schema import Message\r\nimport os\r\nimport re\r\n\r\nclass MultilingualSmartTextProcessor(Component):\r\n    display_name = \"Multilingual Smart Text Processor\"\r\n    description = \"Handle text length with multi-language support and natural text splitting\"\r\n    \r\n    inputs = [\r\n        MessageTextInput(name=\"ai_response\", display_name=\"AI Response\"),\r\n        MessageTextInput(name=\"user_input\", display_name=\"User Input\")\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(display_name=\"Result\", name=\"result\", method=\"process_text\")\r\n    ]\r\n    \r\n    def _get_language_config(self, lang: str) -> dict:\r\n        \"\"\"言語別の設定を取得\"\"\"\r\n        configs = {\r\n            \"ja\": {\r\n                \"sentence_endings\": [\"。\", \"！\", \"？\", \". \", \"! \", \"? \"],\r\n                \"punctuation\": [\"、\", \"，\", \", \"],\r\n                \"paragraph_break\": \"\\n\\n\",\r\n                \"bullet_patterns\": [r'\\n(?=[-*•]\\s)', r'\\n(?=\\d+\\.\\s)', r'\\n(?=[○●◆■]\\s)'],\r\n                \"continue_message\": \"\\n\\nContinue? (Y/N)\",\r\n                \"complete_message\": \"\\n\\n[Response complete]\",\r\n                \"no_content_message\": \"No additional content available.\",\r\n                \"response_ended\": \"Response ended.\",\r\n                \"yes_responses\": [\"Y\", \"YES\", \"はい\", \"続き\", \"つづき\", \"もっと\"],\r\n                \"no_responses\": [\"N\", \"NO\", \"いいえ\", \"終了\", \"やめる\"]\r\n            },\r\n            \"en\": {\r\n                \"sentence_endings\": [\". \", \"! \", \"? \"],\r\n                \"punctuation\": [\", \"],\r\n                \"paragraph_break\": \"\\n\\n\",\r\n                \"bullet_patterns\": [r'\\n(?=[-*•]\\s)', r'\\n(?=\\d+\\.\\s)'],\r\n                \"continue_message\": \"\\n\\nContinue? (Y/N)\",\r\n                \"complete_message\": \"\\n\\n[Response complete]\",\r\n                \"no_content_message\": \"No additional content available.\",\r\n                \"response_ended\": \"Response ended.\",\r\n                \"yes_responses\": [\"Y\", \"YES\"],\r\n                \"no_responses\": [\"N\", \"NO\"]\r\n            },\r\n            \"de\": {\r\n                \"sentence_endings\": [\". \", \"! \", \"? \"],\r\n                \"punctuation\": [\", \"],\r\n                \"paragraph_break\": \"\\n\\n\",\r\n                \"bullet_patterns\": [r'\\n(?=[-*•]\\s)', r'\\n(?=\\d+\\.\\s)'],\r\n                \"continue_message\": \"\\n\\nContinue? (Y/N)\",\r\n                \"complete_message\": \"\\n\\n[Response complete]\",\r\n                \"no_content_message\": \"No additional content available.\",\r\n                \"response_ended\": \"Response ended.\",\r\n                \"yes_responses\": [\"Y\", \"YES\", \"JA\", \"WEITER\", \"FORTSETZEN\"],\r\n                \"no_responses\": [\"N\", \"NO\", \"NEIN\", \"STOPP\", \"ENDE\"]\r\n            },\r\n            \"pt\": {\r\n                \"sentence_endings\": [\". \", \"! \", \"? \"],\r\n                \"punctuation\": [\", \"],\r\n                \"paragraph_break\": \"\\n\\n\",\r\n                \"bullet_patterns\": [r'\\n(?=[-*•]\\s)', r'\\n(?=\\d+\\.\\s)'],\r\n                \"continue_message\": \"\\n\\nContinue? (Y/N)\",\r\n                \"complete_message\": \"\\n\\n[Response complete]\",\r\n                \"no_content_message\": \"No additional content available.\",\r\n                \"response_ended\": \"Response ended.\",\r\n                \"yes_responses\": [\"Y\", \"YES\", \"SIM\", \"CONTINUAR\", \"PROSSEGUIR\"],\r\n                \"no_responses\": [\"N\", \"NO\", \"NÃO\", \"PARAR\", \"FIM\"]\r\n            }\r\n        }\r\n        \r\n        return configs.get(lang, configs[\"en\"])\r\n    \r\n    def _find_natural_break(self, text: str, max_length: int = 500, config: dict = None) -> int:\r\n        \"\"\"言語設定を考慮した自然な区切り位置を見つける\"\"\"\r\n        if len(text) <= max_length:\r\n            return len(text)\r\n        \r\n        if not config:\r\n            config = self._get_language_config(\"en\")\r\n        \r\n        # 検索範囲を設定\r\n        search_start = max(300, max_length - 200)\r\n        search_text = text[search_start:max_length + 100]\r\n        \r\n        # 1. 段落区切りを最優先\r\n        paragraph_match = search_text.rfind(config[\"paragraph_break\"])\r\n        if paragraph_match != -1:\r\n            return search_start + paragraph_match + len(config[\"paragraph_break\"])\r\n        \r\n        # 2. 箇条書きの前で区切る\r\n        for pattern in config[\"bullet_patterns\"]:\r\n            matches = list(re.finditer(pattern, search_text))\r\n            if matches:\r\n                last_match = matches[-1]\r\n                return search_start + last_match.start() + 1\r\n        \r\n        # 3. 文末を探す\r\n        best_pos = -1\r\n        for ending in config[\"sentence_endings\"]:\r\n            pos = search_text.rfind(ending)\r\n            if pos != -1:\r\n                # 番号付きリストの一部でないことを確認\r\n                context = search_text[max(0, pos-5):pos+len(ending)]\r\n                if not re.search(r'\\d+\\.\\s', context):\r\n                    if pos > best_pos:\r\n                        best_pos = pos\r\n        \r\n        if best_pos != -1:\r\n            return search_start + best_pos + len(config[\"sentence_endings\"][0])\r\n        \r\n        # 4. 句読点を探す\r\n        for punct in config[\"punctuation\"]:\r\n            pos = search_text.rfind(punct)\r\n            if pos != -1:\r\n                return search_start + pos + len(punct)\r\n        \r\n        # 5. 改行で区切る（最後の手段）\r\n        newline_pos = search_text.rfind('\\n')\r\n        if newline_pos != -1:\r\n            return search_start + newline_pos + 1\r\n        \r\n        return max_length\r\n    \r\n    def process_text(self) -> Message:\r\n        ai_response = self.ai_response or \"\"\r\n        user_input = (self.user_input or \"\").strip()\r\n        \r\n        # 環境変数から言語情報を取得\r\n        detected_lang = os.environ.get(\"LANGFLOW_DETECTED_LANGUAGE\", \"en\")\r\n        config = self._get_language_config(detected_lang)\r\n        \r\n        # ユーザー入力を正規化\r\n        user_input_upper = user_input.upper()\r\n        \r\n        # Y応答の場合\r\n        is_yes = any(resp.upper() == user_input_upper for resp in config[\"yes_responses\"])\r\n        is_no = any(resp.upper() == user_input_upper for resp in config[\"no_responses\"])\r\n        \r\n        if is_yes:\r\n            stored_text = os.environ.get(\"LANGFLOW_STORED_TEXT\", \"\")\r\n            shown_part = os.environ.get(\"LANGFLOW_SHOWN_PART\", \"\")\r\n            \r\n            if stored_text and shown_part and len(stored_text) > len(shown_part):\r\n                remaining_text = stored_text[len(shown_part):]\r\n                \r\n                # 前回の継続メッセージを除去\r\n                for lang_key in [\"ja\", \"en\", \"de\", \"pt\"]:\r\n                    lang_config = self._get_language_config(lang_key)\r\n                    if lang_config[\"continue_message\"] in remaining_text:\r\n                        remaining_text = remaining_text.replace(lang_config[\"continue_message\"], \"\")\r\n                \r\n                remaining_text = remaining_text.strip()\r\n                \r\n                if len(remaining_text) > 500:\r\n                    break_point = self._find_natural_break(remaining_text, 500, config)\r\n                    next_part = remaining_text[:break_point].strip()\r\n                    \r\n                    new_shown_part = shown_part + next_part\r\n                    os.environ[\"LANGFLOW_SHOWN_PART\"] = new_shown_part\r\n                    \r\n                    if len(stored_text) > len(new_shown_part):\r\n                        return Message(text=next_part + config[\"continue_message\"])\r\n                    else:\r\n                        os.environ.pop(\"LANGFLOW_STORED_TEXT\", None)\r\n                        os.environ.pop(\"LANGFLOW_SHOWN_PART\", None)\r\n                        return Message(text=next_part + config[\"complete_message\"])\r\n                else:\r\n                    os.environ.pop(\"LANGFLOW_STORED_TEXT\", None)\r\n                    os.environ.pop(\"LANGFLOW_SHOWN_PART\", None)\r\n                    return Message(text=remaining_text + config[\"complete_message\"])\r\n            else:\r\n                return Message(text=config[\"no_content_message\"])\r\n        \r\n        # N応答の場合\r\n        elif is_no:\r\n            os.environ.pop(\"LANGFLOW_STORED_TEXT\", None)\r\n            os.environ.pop(\"LANGFLOW_SHOWN_PART\", None)\r\n            return Message(text=config[\"response_ended\"])\r\n        \r\n        # 通常の処理\r\n        else:\r\n            os.environ.pop(\"LANGFLOW_STORED_TEXT\", None)\r\n            os.environ.pop(\"LANGFLOW_SHOWN_PART\", None)\r\n            \r\n            if len(ai_response) > 500:\r\n                break_point = self._find_natural_break(ai_response, 500, config)\r\n                first_part = ai_response[:break_point].strip()\r\n                \r\n                os.environ[\"LANGFLOW_STORED_TEXT\"] = ai_response\r\n                os.environ[\"LANGFLOW_SHOWN_PART\"] = first_part\r\n                \r\n                return Message(text=first_part + config[\"continue_message\"])\r\n            else:\r\n                return Message(text=ai_response)"
              },
              "user_input": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "User Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "user_input",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "MultilingualSmartTextProcessor"
        },
        "dragging": false,
        "id": "MultilingualSmartTextProcessor-wCRnW",
        "measured": {
          "height": 301,
          "width": 320
        },
        "position": {
          "x": 1501.079176765817,
          "y": -126.75225328814874
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "LanguageDetector-zZfnv",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Detect input language and set environment variable for multi-language support",
            "display_name": "Language Detector",
            "documentation": "",
            "edited": true,
            "field_order": [
              "user_input"
            ],
            "frozen": false,
            "legacy": false,
            "lf_version": "1.5.0.post1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Detected Language",
                "group_outputs": false,
                "hidden": null,
                "method": "detect_language",
                "name": "language",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Original Input",
                "group_outputs": false,
                "hidden": null,
                "method": "pass_through_input",
                "name": "original_input",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\r\nfrom langflow.io import MessageTextInput, Output\r\nfrom langflow.schema import Message\r\nimport re\r\nimport os\r\n\r\nclass LanguageDetector(Component):\r\n    display_name = \"Language Detector\"\r\n    description = \"Detect input language and set environment variable for multi-language support\"\r\n    \r\n    inputs = [\r\n        MessageTextInput(name=\"user_input\", display_name=\"User Input\")\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(display_name=\"Detected Language\", name=\"language\", method=\"detect_language\"),\r\n        Output(display_name=\"Original Input\", name=\"original_input\", method=\"pass_through_input\")\r\n    ]\r\n    \r\n    def _is_continuation_input(self, text: str) -> bool:\r\n        \"\"\"継続入力（Y/N）かどうかを判定\"\"\"\r\n        if not text:\r\n            return False\r\n        \r\n        text_clean = text.strip().upper()\r\n        continuation_responses = [\"Y\", \"YES\", \"N\", \"NO\", \"はい\", \"いいえ\", \"続き\", \"つづき\", \r\n                                \"JA\", \"NEIN\", \"WEITER\", \"FORTSETZEN\", \"STOPP\", \"ENDE\",\r\n                                \"SIM\", \"NÃO\", \"CONTINUAR\", \"PROSSEGUIR\", \"PARAR\", \"FIM\", \"やめる\"]\r\n        \r\n        return text_clean in [resp.upper() for resp in continuation_responses]\r\n    \r\n    def _detect_language(self, text: str) -> str:\r\n        \"\"\"言語を検出する改良版\"\"\"\r\n        if not text:\r\n            return \"en\"\r\n        \r\n        # 継続入力の場合は既存の言語設定を維持\r\n        if self._is_continuation_input(text):\r\n            existing_lang = os.environ.get(\"LANGFLOW_DETECTED_LANGUAGE\", \"en\")\r\n            return existing_lang\r\n        \r\n        # テキストの長さを正規化（スペースと句読点を除く）\r\n        cleaned_text = re.sub(r'[^\\w]', '', text)\r\n        if not cleaned_text:\r\n            return \"en\"\r\n        \r\n        # 各言語の文字を検出\r\n        hiragana_chars = re.findall(r'[\\u3040-\\u309F]', text)  # ひらがな\r\n        katakana_chars = re.findall(r'[\\u30A0-\\u30FF]', text)  # カタカナ\r\n        \r\n        # 日本語特有の表現をチェック\r\n        japanese_patterns = [\r\n            r'こんにち[はわ]', r'ありがと', r'です', r'ます', r'である', \r\n            r'について', r'してください', r'でしょう', r'かもしれ', r'だと思'\r\n        ]\r\n        \r\n        # ドイツ語特有の表現をチェック\r\n        german_patterns = [\r\n            r'ich bin', r'wie geht', r'danke', r'bitte', r'können sie', r'möchten',\r\n            r'ß', r'ä', r'ö', r'ü', r'der die das', r'und'\r\n        ]\r\n        \r\n        # ポルトガル語特有の表現をチェック  \r\n        portuguese_patterns = [\r\n            r'obrigad[oa]', r'por favor', r'como está', r'eu sou', r'você', r'não',\r\n            r'ã', r'õ', r'ç', r'á', r'é', r'í', r'ó', r'ú'\r\n        ]\r\n        \r\n        # 判定ロジック\r\n        \r\n        # ひらがな・カタカナがあれば確実に日本語\r\n        if hiragana_chars or katakana_chars:\r\n            return \"ja\"\r\n        \r\n        # 日本語特有の表現があれば日本語\r\n        for pattern in japanese_patterns:\r\n            if re.search(pattern, text):\r\n                return \"ja\"\r\n        \r\n        # ドイツ語特有の文字・表現があればドイツ語\r\n        for pattern in german_patterns:\r\n            if re.search(pattern, text, re.IGNORECASE):\r\n                return \"de\"\r\n        \r\n        # ポルトガル語特有の文字・表現があればポルトガル語\r\n        for pattern in portuguese_patterns:\r\n            if re.search(pattern, text, re.IGNORECASE):\r\n                return \"pt\"\r\n        \r\n        # アルファベットがあれば英語\r\n        if re.search(r'[a-zA-Z]', text):\r\n            return \"en\"\r\n        \r\n        return \"en\"  # デフォルトは英語\r\n    \r\n    def detect_language(self) -> Message:\r\n        user_input = self.user_input or \"\"\r\n        detected_lang = self._detect_language(user_input)\r\n        \r\n        # 環境変数に言語情報を保存（継続入力でない場合のみ更新）\r\n        if not self._is_continuation_input(user_input):\r\n            os.environ[\"LANGFLOW_DETECTED_LANGUAGE\"] = detected_lang\r\n        \r\n        # デバッグ情報を含めて返す\r\n        is_continuation = self._is_continuation_input(user_input)\r\n        debug_info = f\"[DEBUG] Input: '{user_input}' | Detected: {detected_lang} | IsContinuation: {is_continuation}\"\r\n        return Message(text=f\"{detected_lang}|{debug_info}\")\r\n    \r\n    def pass_through_input(self) -> Message:\r\n        user_input = self.user_input or \"\"\r\n        \r\n        # 継続入力の場合は、純粋な入力をそのまま返す\r\n        if self._is_continuation_input(user_input):\r\n            return Message(text=user_input)\r\n        \r\n        # 通常の入力の場合のみ言語情報を付加（オプション）\r\n        detected_lang = os.environ.get(\"LANGFLOW_DETECTED_LANGUAGE\", \"en\")\r\n        return Message(text=user_input)"
              },
              "user_input": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "User Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "user_input",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "selected_output": "language",
          "showNode": true,
          "type": "LanguageDetector"
        },
        "dragging": false,
        "id": "LanguageDetector-zZfnv",
        "measured": {
          "height": 219,
          "width": 320
        },
        "position": {
          "x": -295.55862391138083,
          "y": -371.6498183797544
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": 248.12660824912282,
      "y": 493.1942363724662,
      "zoom": 0.30069606299760404
    }
  },
  "description": "長文管理完了：ユーザーのY/Nで判断\n多言語管理\n⇒ 8/12 多言語（日英）認識OK\n　 Cohere EnbeddingsのModelを\n     embed-multilingual-v3.0に変更\n　 FIASSのPersist Directryを./faiss_db_refreshに変更",
  "endpoint_name": null,
  "id": "4ae7c48b-01f2-42a1-9017-dd937aed953a",
  "is_component": false,
  "last_tested_version": "1.5.0.post1",
  "name": "TestBot_GitHub",
  "tags": []
}